{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models, datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device to use (CPU or GPU). CUDA = GPU support for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Using: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main data directory\n",
    "DATA_DIR = 'tiny-imagenet-200-test' # Original images come in shapes of [3,64,64]\n",
    "\n",
    "# Define training and validation data paths\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train') \n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup function to create dataloaders for image datasets\n",
    "def generate_dataloader(data, name, transform=None):\n",
    "    if data is None: \n",
    "        return None\n",
    "    \n",
    "    # Read image files to pytorch dataset using ImageFolder, a generic data \n",
    "    # loader where images are in format root/label/filename\n",
    "    # See https://pytorch.org/vision/stable/datasets.html\n",
    "    if transform is None:\n",
    "        dataset = datasets.ImageFolder(data, transform=T.ToTensor())\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Set options for device\n",
    "    if use_cuda:\n",
    "        kwargs = {\"pin_memory\": True, \"num_workers\": 1}\n",
    "    else:\n",
    "        kwargs = {}\n",
    "    \n",
    "    # Wrap image dataset (defined above) in dataloader \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                        shuffle=(name==\"train\"), \n",
    "                        **kwargs)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate validation subfolders for the validation images based on\n",
    "# their labels indicated in the val_annotations txt file\n",
    "val_img_dir = os.path.join(VALID_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation sequence for image pre-processing\n",
    "# If not using pre-trained model, normalize with 0.5, 0.5, 0.5 (mean and SD)\n",
    "# If using pre-trained ImageNet, normalize with mean=[0.485, 0.456, 0.406], \n",
    "# std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess_transform_pretrain = T.Compose([\n",
    "                T.Resize(224), # Resize images to 256 x 256\n",
    "                #T.CenterCrop(224), # Center crop image\n",
    "                #T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),  # Converting cropped images to tensors\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "simple = T.Compose([T.ToTensor(),  # Converting cropped images to tensors\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size for DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders for pre-trained models (normalized based on specific requirements)\n",
    "train_loader = generate_dataloader(TRAIN_DIR, \"train\", preprocess_transform_pretrain)\n",
    "\n",
    "val_loader= generate_dataloader(val_img_dir, \"val\", preprocess_transform_pretrain)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
